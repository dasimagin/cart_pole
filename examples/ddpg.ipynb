{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4d06497",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import collections\n",
    "import json\n",
    "import sys\n",
    "import random\n",
    "import time\n",
    "import torch\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from copy import deepcopy\n",
    "from dataclasses import dataclass\n",
    "from torch import FloatTensor\n",
    "from typing import Collection\n",
    "from tqdm import tqdm\n",
    "\n",
    "from cartpole import LogServer, State, Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60cf03b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# System parameters\n",
    "\n",
    "@dataclass(init=False)\n",
    "@dataclass\n",
    "class Limits:\n",
    "    position: float = 0.25\n",
    "    velocity: float = 3.0\n",
    "    angle: float = 3 * torch.pi * 2 # no more 2 rotations \n",
    "    acceleration: float = 2.5\n",
    "\n",
    "@dataclass(init=False)\n",
    "class DynamicSystemConfig:\n",
    "    gravity: float = 9.8\n",
    "    pole_length: float = 0.3\n",
    "    limits = Limits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "30f7674b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple simulation based on dynamics\n",
    "\n",
    "@dataclass(init=False)\n",
    "class SimulatorConfig:\n",
    "    integration_interval: float = 0.02\n",
    "    integration_step_n: int = 20\n",
    "\n",
    "    @property\n",
    "    def time_delta(self) -> float:\n",
    "        return self.integration_interval / self.integration_step_n\n",
    "\n",
    "class Simulator:\n",
    "    def __init__(self, dynamics = DynamicSystemConfig(), config = SimulatorConfig()):\n",
    "        self.dynamics = dynamics\n",
    "        self.config = config\n",
    "\n",
    "    def derivative(self, s: FloatTensor, a: FloatTensor) -> FloatTensor:\n",
    "        result = torch.empty_like(s)\n",
    "        theta = s[1]\n",
    "\n",
    "        g = self.dynamics.gravity\n",
    "        l = self.dynamics.pole_length\n",
    "\n",
    "        result[0] = s[2]\n",
    "        result[1] = s[3]\n",
    "        result[2] = a\n",
    "        result[3] = -1.5 / l * (a * torch.cos(theta) + g * torch.sin(theta))\n",
    "\n",
    "        return result\n",
    "\n",
    "\n",
    "    def advance(self, x: FloatTensor, a: FloatTensor) -> FloatTensor:\n",
    "        x = x.clone()\n",
    "        dt = self.config.time_delta\n",
    "\n",
    "        for _ in range(self.config.integration_step_n):\n",
    "            ds1 = self.derivative(x, a)\n",
    "            ds2 = self.derivative(x + ds1 * dt, a)\n",
    "            x += (ds1 + ds2) / 2 * dt\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66524385",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment\n",
    "\n",
    "class Environment:\n",
    "    def __init__(self, dynamics = DynamicSystemConfig(), config = SimulatorConfig()):\n",
    "        self.dynamics = dynamics\n",
    "        self.simulator = Simulator(dynamics, config)\n",
    "\n",
    "    def is_finish(self, s: FloatTensor) -> bool:\n",
    "        return s[0].abs() >= self.dynamics.limits.position \\\n",
    "            or s[2].abs() >= self.dynamics.limits.velocity \\\n",
    "            or s[1].abs() >= self.dynamics.limits.angle\n",
    "\n",
    "\n",
    "    def reset(self) -> FloatTensor:\n",
    "        s = torch.zeros(4, 1)\n",
    "        # s[1].uniform_(-torch.pi + 1e-3, torch.pi - 1e-3)\n",
    "        s[1].normal_(torch.pi, 0.1)\n",
    "        return s\n",
    "\n",
    "    def reward(self, s: FloatTensor, a: FloatTensor) -> float:\n",
    "        angle_reward = torch.exp(1-torch.cos(s[1])) + 0.3 * (1 - s[3].abs() / self.dynamics.limits.angle) - 0.26\n",
    "        return angle_reward\n",
    "\n",
    "    def advance(self, s: FloatTensor, a: FloatTensor) -> FloatTensor:\n",
    "        s_next = self.simulator.advance(s, a)\n",
    "        return s_next, self.reward(s_next, a), self.is_finish(s_next)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b7bad42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replay buffer\n",
    "\n",
    "@dataclass\n",
    "class Transition:\n",
    "    state: FloatTensor\n",
    "    action: FloatTensor\n",
    "    next_state: FloatTensor\n",
    "    reward: float\n",
    "    is_finish: bool\n",
    "\n",
    "class ReplayBuffer:\n",
    "    def __init__(self, capacity: int):\n",
    "        self.capacity = capacity\n",
    "        self.buffer = collections.deque()\n",
    "\n",
    "    def push(self, transition):\n",
    "        self.buffer.append(transition)\n",
    "        if len(self.buffer) > self.capacity:\n",
    "            self.buffer.popleft()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.buffer)\n",
    "\n",
    "    def sample(self, batch_n: int) -> Collection[FloatTensor]:\n",
    "        batch = random.sample(self.buffer, batch_n)\n",
    "        s = torch.hstack([t.state for t in batch])\n",
    "        s_next = torch.hstack([t.next_state for t in batch])\n",
    "\n",
    "        a = torch.tensor([t.action for t in batch])\n",
    "        r = torch.tensor([t.reward for t in batch])\n",
    "        finish = torch.tensor([t.is_finish for t in batch])\n",
    "\n",
    "        return s, a, s_next, r, finish\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c453db08",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Actor(torch.nn.Module):\n",
    "    def __init__(self, limits: Limits):\n",
    "        super(Actor, self).__init__()\n",
    "\n",
    "        self.temprature = 0.01\n",
    "        self.limits = limits\n",
    "\n",
    "        self.l1 = torch.nn.Linear(6, 64)\n",
    "        self.l2 = torch.nn.Linear(64, 256)\n",
    "        self.l3 = torch.nn.Linear(256, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        _, batch_n = x.shape\n",
    "        f = FloatTensor(6, batch_n)\n",
    "\n",
    "        f[0] = x[0] / self.limits.position\n",
    "        f[1] = x[2] / self.limits.velocity\n",
    "        f[2] = x[3] / (2*torch.pi)\n",
    "\n",
    "        f[3] = x[1] / self.limits.angle\n",
    "        f[4] = torch.cos(x[1])\n",
    "        f[5] = torch.sin(x[1])\n",
    "\n",
    "        f = f.T\n",
    "        f = self.l1(f)\n",
    "        f = torch.tanh(f)\n",
    "        f = self.l2(f)\n",
    "        f = torch.tanh(f)\n",
    "        f = self.l3(f)\n",
    "        a = torch.tanh(self.temprature * f)\n",
    "\n",
    "        return self.limits.acceleration * a.flatten()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fbbecf6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Critic(torch.nn.Module):\n",
    "    def __init__(self,limits: Limits):\n",
    "        super(Critic, self).__init__()\n",
    "\n",
    "        self.limits = limits\n",
    "\n",
    "        self.layers = torch.nn.Sequential(\n",
    "            torch.nn.Linear(7, 64),\n",
    "            torch.nn.Tanh(),\n",
    "            torch.nn.Linear(64, 256),\n",
    "            torch.nn.Tanh(),\n",
    "            torch.nn.Linear(256, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x, a):\n",
    "        _, batch_n = x.shape\n",
    "        features = FloatTensor(7, batch_n)\n",
    "\n",
    "        features[0] = x[0] / self.limits.position\n",
    "        features[1] = x[2] / self.limits.velocity\n",
    "        features[2] = x[3] / (2*torch.pi)\n",
    "        features[3] = a / self.limits.acceleration\n",
    "       \n",
    "        features[4] = x[1] / (2*torch.pi)\n",
    "        features[5] = torch.cos(x[1])\n",
    "        features[6] = torch.sin(x[1])\n",
    "\n",
    "        q_value = self.layers(features.T)\n",
    "        return q_value.flatten()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d798f094",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-24 02:27:19,827: [INFO] Starting server...\n",
      "2022-12-24 02:27:19,829: [INFO] Server listening on ('0.0.0.0', 8765)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Init replay buffer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 1/30 [00:00<00:03,  7.36it/s]2022-12-24 02:27:19,992: [INFO] Connection to ('127.0.0.1', 35766) opened via /\n",
      "2022-12-24 02:27:19,998: [DEBUG] Got message: {'op': 'subscribe', 'subscriptions': [{'id': 0, 'channelId': 0}]}\n",
      "2022-12-24 02:27:19,998: [DEBUG] Client ('127.0.0.1', 35766) subscribed to channel 0\n",
      "100%|██████████| 30/30 [00:04<00:00,  6.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 182/1000 [11:56<53:40,  3.94s/it]  \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 82\u001b[0m\n\u001b[1;32m     79\u001b[0m foxglove\u001b[39m.\u001b[39mpublish(State(s[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mitem(), s[\u001b[39m2\u001b[39m]\u001b[39m.\u001b[39mitem(), s[\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mitem(), s[\u001b[39m3\u001b[39m]\u001b[39m.\u001b[39mitem(), Error\u001b[39m.\u001b[39mNO_ERROR, a\u001b[39m.\u001b[39mitem()))\n\u001b[1;32m     80\u001b[0m s \u001b[39m=\u001b[39m s_next\u001b[39m.\u001b[39mdetach()\n\u001b[0;32m---> 82\u001b[0m critic_loss, actor_reward \u001b[39m=\u001b[39m update()\n\u001b[1;32m     83\u001b[0m mutate(actor, actor_target)\n\u001b[1;32m     84\u001b[0m mutate(critic, critic_target)\n",
      "Cell \u001b[0;32mIn[8], line 49\u001b[0m, in \u001b[0;36mupdate\u001b[0;34m()\u001b[0m\n\u001b[1;32m     47\u001b[0m actor_optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m     48\u001b[0m actor_loss\u001b[39m.\u001b[39mbackward()\n\u001b[0;32m---> 49\u001b[0m actor_optimizer\u001b[39m.\u001b[39;49mstep()\n\u001b[1;32m     51\u001b[0m \u001b[39mreturn\u001b[39;00m critic_loss, \u001b[39m-\u001b[39mactor_loss\n",
      "File \u001b[0;32m~/cart_pole/.venv/lib/python3.10/site-packages/torch/optim/optimizer.py:140\u001b[0m, in \u001b[0;36mOptimizer._hook_for_profile.<locals>.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m profile_name \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mOptimizer.step#\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m.step\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(obj\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m)\n\u001b[1;32m    139\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mautograd\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mrecord_function(profile_name):\n\u001b[0;32m--> 140\u001b[0m     out \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    141\u001b[0m     obj\u001b[39m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    142\u001b[0m     \u001b[39mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/cart_pole/.venv/lib/python3.10/site-packages/torch/optim/optimizer.py:23\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     22\u001b[0m     torch\u001b[39m.\u001b[39mset_grad_enabled(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdefaults[\u001b[39m'\u001b[39m\u001b[39mdifferentiable\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m---> 23\u001b[0m     ret \u001b[39m=\u001b[39m func(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     24\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     25\u001b[0m     torch\u001b[39m.\u001b[39mset_grad_enabled(prev_grad)\n",
      "File \u001b[0;32m~/cart_pole/.venv/lib/python3.10/site-packages/torch/optim/adam.py:234\u001b[0m, in \u001b[0;36mAdam.step\u001b[0;34m(self, closure, grad_scaler)\u001b[0m\n\u001b[1;32m    231\u001b[0m                 \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39m`requires_grad` is not supported for `step` in differentiable mode\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    232\u001b[0m             state_steps\u001b[39m.\u001b[39mappend(state[\u001b[39m'\u001b[39m\u001b[39mstep\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m--> 234\u001b[0m     adam(params_with_grad,\n\u001b[1;32m    235\u001b[0m          grads,\n\u001b[1;32m    236\u001b[0m          exp_avgs,\n\u001b[1;32m    237\u001b[0m          exp_avg_sqs,\n\u001b[1;32m    238\u001b[0m          max_exp_avg_sqs,\n\u001b[1;32m    239\u001b[0m          state_steps,\n\u001b[1;32m    240\u001b[0m          amsgrad\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mamsgrad\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    241\u001b[0m          beta1\u001b[39m=\u001b[39;49mbeta1,\n\u001b[1;32m    242\u001b[0m          beta2\u001b[39m=\u001b[39;49mbeta2,\n\u001b[1;32m    243\u001b[0m          lr\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mlr\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    244\u001b[0m          weight_decay\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mweight_decay\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    245\u001b[0m          eps\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39meps\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    246\u001b[0m          maximize\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mmaximize\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    247\u001b[0m          foreach\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mforeach\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    248\u001b[0m          capturable\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mcapturable\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    249\u001b[0m          differentiable\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mdifferentiable\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    250\u001b[0m          fused\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mfused\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    251\u001b[0m          grad_scale\u001b[39m=\u001b[39;49mgrad_scale,\n\u001b[1;32m    252\u001b[0m          found_inf\u001b[39m=\u001b[39;49mfound_inf)\n\u001b[1;32m    254\u001b[0m \u001b[39mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m~/cart_pole/.venv/lib/python3.10/site-packages/torch/optim/adam.py:300\u001b[0m, in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    297\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    298\u001b[0m     func \u001b[39m=\u001b[39m _single_tensor_adam\n\u001b[0;32m--> 300\u001b[0m func(params,\n\u001b[1;32m    301\u001b[0m      grads,\n\u001b[1;32m    302\u001b[0m      exp_avgs,\n\u001b[1;32m    303\u001b[0m      exp_avg_sqs,\n\u001b[1;32m    304\u001b[0m      max_exp_avg_sqs,\n\u001b[1;32m    305\u001b[0m      state_steps,\n\u001b[1;32m    306\u001b[0m      amsgrad\u001b[39m=\u001b[39;49mamsgrad,\n\u001b[1;32m    307\u001b[0m      beta1\u001b[39m=\u001b[39;49mbeta1,\n\u001b[1;32m    308\u001b[0m      beta2\u001b[39m=\u001b[39;49mbeta2,\n\u001b[1;32m    309\u001b[0m      lr\u001b[39m=\u001b[39;49mlr,\n\u001b[1;32m    310\u001b[0m      weight_decay\u001b[39m=\u001b[39;49mweight_decay,\n\u001b[1;32m    311\u001b[0m      eps\u001b[39m=\u001b[39;49meps,\n\u001b[1;32m    312\u001b[0m      maximize\u001b[39m=\u001b[39;49mmaximize,\n\u001b[1;32m    313\u001b[0m      capturable\u001b[39m=\u001b[39;49mcapturable,\n\u001b[1;32m    314\u001b[0m      differentiable\u001b[39m=\u001b[39;49mdifferentiable,\n\u001b[1;32m    315\u001b[0m      grad_scale\u001b[39m=\u001b[39;49mgrad_scale,\n\u001b[1;32m    316\u001b[0m      found_inf\u001b[39m=\u001b[39;49mfound_inf)\n",
      "File \u001b[0;32m~/cart_pole/.venv/lib/python3.10/site-packages/torch/optim/adam.py:410\u001b[0m, in \u001b[0;36m_single_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[1;32m    408\u001b[0m     denom \u001b[39m=\u001b[39m (max_exp_avg_sqs[i]\u001b[39m.\u001b[39msqrt() \u001b[39m/\u001b[39m bias_correction2_sqrt)\u001b[39m.\u001b[39madd_(eps)\n\u001b[1;32m    409\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 410\u001b[0m     denom \u001b[39m=\u001b[39m (exp_avg_sq\u001b[39m.\u001b[39;49msqrt() \u001b[39m/\u001b[39;49m bias_correction2_sqrt)\u001b[39m.\u001b[39;49madd_(eps)\n\u001b[1;32m    412\u001b[0m param\u001b[39m.\u001b[39maddcdiv_(exp_avg, denom, value\u001b[39m=\u001b[39m\u001b[39m-\u001b[39mstep_size)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "foxglove = LogServer(log_path='log.mcap')\n",
    "\n",
    "dynamic_system_config = DynamicSystemConfig()\n",
    "simulator_config = SimulatorConfig()\n",
    "\n",
    "cart_pole = Environment(dynamic_system_config, simulator_config)\n",
    "buffer = ReplayBuffer(3000)\n",
    "\n",
    "actor = Actor(dynamic_system_config.limits)\n",
    "actor_target = Actor(dynamic_system_config.limits)\n",
    "actor_optimizer = torch.optim.Adam(actor.parameters())\n",
    "\n",
    "\n",
    "critic = Critic(dynamic_system_config.limits)\n",
    "critic_target = Critic(dynamic_system_config.limits)\n",
    "critic_optimizer = torch.optim.Adam(critic.parameters())\n",
    "\n",
    "gamma = 0.99\n",
    "batch_n = 512\n",
    "tau = 0.999\n",
    "decay = 0.99\n",
    "sigma = 0.1\n",
    "\n",
    "def mutate(current_net, target_net):\n",
    "    current_net_dict = current_net.state_dict()\n",
    "    target_net_dict = target_net.state_dict()\n",
    "    \n",
    "    for key in target_net_dict:\n",
    "        target_net_dict[key] = tau * current_net_dict[key] + (1 - tau) * target_net_dict[key]\n",
    "        target_net.load_state_dict(target_net_dict)\n",
    "\n",
    "def update():\n",
    "    s, a, s_next, r, finish = buffer.sample(batch_n)\n",
    "\n",
    "    q_value = critic(s, a)\n",
    "    q_value_next = critic_target(s_next, actor_target(s_next)).detach()\n",
    "    q_value_next[finish] = 0\n",
    "\n",
    "    q_target = r + gamma * q_value_next\n",
    "\n",
    "    critic_loss = torch.nn.functional.mse_loss(q_value, q_target)\n",
    "    critic_optimizer.zero_grad()\n",
    "    critic_loss.backward()\n",
    "    critic_optimizer.step()\n",
    "\n",
    "    actor_loss = -critic(s, actor(s)).mean()\n",
    "    actor_optimizer.zero_grad()\n",
    "    actor_loss.backward()\n",
    "    actor_optimizer.step()\n",
    "\n",
    "    return critic_loss, -actor_loss\n",
    "\n",
    "print(\"Init replay buffer...\")\n",
    "for _ in tqdm(range(30)):\n",
    "    s = cart_pole.reset()\n",
    "    a = torch.tensor([0.0])\n",
    "    for _ in range(100):\n",
    "        s_next, r, finish = cart_pole.advance(s, a)\n",
    "        buffer.push(Transition(s, a,s_next, r, finish))\n",
    "\n",
    "session_n = 1000\n",
    "max_session_size = 2000\n",
    "\n",
    "print('Training...')\n",
    "\n",
    "counter = 0\n",
    "for _ in tqdm(range(session_n)):\n",
    "    s = cart_pole.reset()\n",
    "    # print(s)\n",
    "\n",
    "    sigma *= decay\n",
    "\n",
    "    for _ in range(max_session_size):\n",
    "        with torch.no_grad():\n",
    "            a = actor(s).detach() + torch.randn(1) * sigma\n",
    "        s_next, r, finish = cart_pole.advance(s, a)\n",
    "\n",
    "        buffer.push(Transition(s, a, s_next, r, finish))\n",
    "        foxglove.publish(State(s[0].item(), s[2].item(), s[1].item(), s[3].item(), Error.NO_ERROR, a.item()))\n",
    "        s = s_next.detach()\n",
    "\n",
    "        critic_loss, actor_reward = update()\n",
    "        mutate(actor, actor_target)\n",
    "        mutate(critic, critic_target)\n",
    "\n",
    "        counter += 1\n",
    "        if finish:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226f4bff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "a243db9845111fb0c3af60b87049d7cd77706b321c47596828fa832e02c74834"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
